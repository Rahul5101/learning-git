{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21975a01",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e0d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  \n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.patches import ConnectionPatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557eabe3",
   "metadata": {},
   "source": [
    "# Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3023332",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f64fb",
   "metadata": {},
   "source": [
    "# Visualization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58994212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c28b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking for Collinearity to avoid overfitting\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# from statsmodels.tools.tools import add_constant\n",
    "\n",
    "\n",
    "# df_train_with_const = add_constant(df_train) \n",
    "\n",
    "\n",
    "# vif_data = pd.DataFrame()\n",
    "# vif_data[\"feature\"] = df_train_with_const.columns\n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(df_train_with_const.values, i) for i in range(df_train_with_const.shape[1])]\n",
    "\n",
    "# print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd0bc8d",
   "metadata": {},
   "source": [
    "Checking collinearity helps in machine learning by identifying highly correlated features, which can negatively impact model performance. High collinearity can lead to multicollinearity, where redundant information affects the model's ability to interpret the importance of features, increases variance, and may cause overfitting. Reducing collinearity by removing or combining correlated features improves model accuracy, interpretability, and generalization.\n",
    "    \n",
    "    Variance Inflation Factor (VIF) is a measure used to detect the severity of multicollinearity in regression analysis. It quantifies how much the variance of a regression coefficient is inflated due to collinearity with other predictor variables.\n",
    "\n",
    "Mathematically, VIF is calculated as:\n",
    "\n",
    "                            VIF_i = 1 / (1-R_i ^ 2)\n",
    "                          \n",
    "Where, \n",
    "    VIF_i : Variance Inflation Factor for the ith predictor ,\n",
    "    R_i ^ 2 : R ^ 2 value of the ith predictor.\n",
    "    \n",
    "A VIF value:\n",
    "    1: No correlation between the predictor and other predictors ,\n",
    "    VIF > 5 or 10: Indicates high multicollinearity, which could affect model performance.\n",
    "   \n",
    "Reducing VIF by removing or combining highly correlated features can improve model stability and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7204d3-79aa-407c-80aa-9d4edd46c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix = df_train.corr()\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".1f\", linewidths=0.2)\n",
    "# plt.gcf().set_facecolor('#ffff')  \n",
    "# plt.title('Correlation Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04adc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.drop(columns=['id'], inplace=True)\n",
    "# df_test.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84941c24-8074-4ba8-bf10-fb197184134c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d52d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['FloodProbability'] \n",
    "df_train = df_train.drop(['FloodProbability'],axis=1)\n",
    "X = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "764c5b22-9f98-4a0d-bd37-be22ffd97536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0.445\n",
       "1          0.450\n",
       "2          0.530\n",
       "3          0.535\n",
       "4          0.415\n",
       "           ...  \n",
       "1117952    0.495\n",
       "1117953    0.480\n",
       "1117954    0.485\n",
       "1117955    0.495\n",
       "1117956    0.560\n",
       "Name: FloodProbability, Length: 1117957, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d21cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a000902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']\n"
     ]
    }
   ],
   "source": [
    "print(df_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0928461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>...</th>\n",
       "      <th>IneffectiveDisasterPreparedness</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117957</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117958</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1117959</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117960</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117961</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745300</th>\n",
       "      <td>1863257</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745301</th>\n",
       "      <td>1863258</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745302</th>\n",
       "      <td>1863259</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745303</th>\n",
       "      <td>1863260</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745304</th>\n",
       "      <td>1863261</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>745305 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  MonsoonIntensity  TopographyDrainage  RiverManagement  \\\n",
       "0       1117957                 4                   6                3   \n",
       "1       1117958                 4                   4                2   \n",
       "2       1117959                 1                   3                6   \n",
       "3       1117960                 2                   4                4   \n",
       "4       1117961                 6                   3                2   \n",
       "...         ...               ...                 ...              ...   \n",
       "745300  1863257                 5                   4                8   \n",
       "745301  1863258                 4                   4                2   \n",
       "745302  1863259                 5                   7                9   \n",
       "745303  1863260                 4                   7                6   \n",
       "745304  1863261                 4                   2                5   \n",
       "\n",
       "        Deforestation  Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "0                   5             6              7            8          7   \n",
       "1                   9             5              5            4          7   \n",
       "2                   5             7              2            4          6   \n",
       "3                   6             4              5            4          3   \n",
       "4                   4             6              4            5          5   \n",
       "...               ...           ...            ...          ...        ...   \n",
       "745300              3             5              4            4          5   \n",
       "745301             12             4              3            4          3   \n",
       "745302              5             5              6            7          5   \n",
       "745303              3             5              2            3          8   \n",
       "745304              3             8              4            5          3   \n",
       "\n",
       "        AgriculturalPractices  ...  IneffectiveDisasterPreparedness  \\\n",
       "0                           8  ...                                8   \n",
       "1                           5  ...                                2   \n",
       "2                           4  ...                                7   \n",
       "3                           4  ...                                7   \n",
       "4                           3  ...                                4   \n",
       "...                       ...  ...                              ...   \n",
       "745300                      5  ...                                5   \n",
       "745301                      5  ...                                3   \n",
       "745302                      5  ...                                6   \n",
       "745303                      6  ...                                6   \n",
       "745304                      5  ...                                4   \n",
       "\n",
       "        DrainageSystems  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "0                     5                     7           5           6   \n",
       "1                     4                     7           4           5   \n",
       "2                     9                     2           5           5   \n",
       "3                     8                     4           6           7   \n",
       "4                     3                     2           6           4   \n",
       "...                 ...                   ...         ...         ...   \n",
       "745300                6                     1           3           5   \n",
       "745301                7                     4           4           3   \n",
       "745302               11                     3          11           4   \n",
       "745303                6                     8           6           2   \n",
       "745304                2                     6          10           4   \n",
       "\n",
       "        DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "0                                 3                6            4   \n",
       "1                                 1                7            4   \n",
       "2                                 2                3            6   \n",
       "3                                 6                4            2   \n",
       "4                                 6                8            4   \n",
       "...                             ...              ...          ...   \n",
       "745300                            6                4            4   \n",
       "745301                            5                5            3   \n",
       "745302                            5                9            5   \n",
       "745303                            3                8            7   \n",
       "745304                            3                9            8   \n",
       "\n",
       "        InadequatePlanning  PoliticalFactors  \n",
       "0                        4                 5  \n",
       "1                        4                 3  \n",
       "2                        8                 3  \n",
       "3                        4                 4  \n",
       "4                        5                 5  \n",
       "...                    ...               ...  \n",
       "745300                   6                 6  \n",
       "745301                   5                 4  \n",
       "745302                   5                 4  \n",
       "745303                   5                 5  \n",
       "745304                   6                 3  \n",
       "\n",
       "[745305 rows x 21 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b321c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>...</th>\n",
       "      <th>IneffectiveDisasterPreparedness</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117952</th>\n",
       "      <td>1117952</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117953</th>\n",
       "      <td>1117953</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117954</th>\n",
       "      <td>1117954</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117955</th>\n",
       "      <td>1117955</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117956</th>\n",
       "      <td>1117956</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1117957 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  MonsoonIntensity  TopographyDrainage  RiverManagement  \\\n",
       "0              0                 5                   8                5   \n",
       "1              1                 6                   7                4   \n",
       "2              2                 6                   5                6   \n",
       "3              3                 3                   4                6   \n",
       "4              4                 5                   3                2   \n",
       "...          ...               ...                 ...              ...   \n",
       "1117952  1117952                 3                   3                4   \n",
       "1117953  1117953                 2                   2                4   \n",
       "1117954  1117954                 7                   3                9   \n",
       "1117955  1117955                 7                   3                3   \n",
       "1117956  1117956                 4                   5                6   \n",
       "\n",
       "         Deforestation  Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "0                    8             6              4            4          3   \n",
       "1                    4             8              8            3          5   \n",
       "2                    7             3              7            1          5   \n",
       "3                    5             4              8            4          7   \n",
       "4                    6             4              4            3          3   \n",
       "...                ...           ...            ...          ...        ...   \n",
       "1117952             10             4              5            5          7   \n",
       "1117953              3             9              5            8          1   \n",
       "1117954              4             6              5            9          1   \n",
       "1117955              7             5              2            3          4   \n",
       "1117956              9             5              5            2          8   \n",
       "\n",
       "         AgriculturalPractices  ...  IneffectiveDisasterPreparedness  \\\n",
       "0                            3  ...                                2   \n",
       "1                            4  ...                                9   \n",
       "2                            4  ...                                6   \n",
       "3                            6  ...                                5   \n",
       "4                            3  ...                                5   \n",
       "...                        ...  ...                              ...   \n",
       "1117952                     10  ...                                3   \n",
       "1117953                      3  ...                                5   \n",
       "1117954                      3  ...                                5   \n",
       "1117955                      6  ...                                6   \n",
       "1117956                      4  ...                                1   \n",
       "\n",
       "         DrainageSystems  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "0                      5                     3           3           5   \n",
       "1                      7                     2           0           3   \n",
       "2                      7                     3           7           5   \n",
       "3                      2                     4           7           4   \n",
       "4                      2                     2           6           6   \n",
       "...                  ...                   ...         ...         ...   \n",
       "1117952                7                     8           7           2   \n",
       "1117953                9                     4           4           3   \n",
       "1117954                5                     5           5           5   \n",
       "1117955                6                     8           5           3   \n",
       "1117956                4                     8           6           5   \n",
       "\n",
       "         DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "0                                  4                7            5   \n",
       "1                                  5                3            3   \n",
       "2                                  6                8            2   \n",
       "3                                  4                6            5   \n",
       "4                                  4                1            2   \n",
       "...                              ...              ...          ...   \n",
       "1117952                            2                1            4   \n",
       "1117953                            7                4            9   \n",
       "1117954                            6                5            5   \n",
       "1117955                            4                6            7   \n",
       "1117956                            5                6            7   \n",
       "\n",
       "         InadequatePlanning  PoliticalFactors  \n",
       "0                         7                 3  \n",
       "1                         4                 3  \n",
       "2                         3                 3  \n",
       "3                         7                 5  \n",
       "4                         3                 5  \n",
       "...                     ...               ...  \n",
       "1117952                   6                 4  \n",
       "1117953                   4                 5  \n",
       "1117954                   2                 4  \n",
       "1117955                   6                 4  \n",
       "1117956                   7                 8  \n",
       "\n",
       "[1117957 rows x 21 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014fa9f7",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fee4677",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming X contains your training features and y contains the target variable\u001b[39;00m\n\u001b[1;32m      5\u001b[0m reg \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m----> 6\u001b[0m reg\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Ensure df_test contains only the features used in training\u001b[39;00m\n\u001b[1;32m      9\u001b[0m feature_columns \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns  \u001b[38;5;66;03m# Get feature names from the training set\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming X contains your training features and y contains the target variable\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Ensure df_test contains only the features used in training\n",
    "feature_columns = X_train.columns  # Get feature names from the training set\n",
    "\n",
    "# Select only the feature columns in df_test\n",
    "X_test_cleaned = X_test[feature_columns]\n",
    "\n",
    "# Predicting the target on the cleaned test dataset\n",
    "pred = reg.predict(X_test_cleaned)\n",
    "\n",
    "# Create a new DataFrame that combines the test data and predictions\n",
    "combined_results = pd.concat([df_test.reset_index(drop=True), \n",
    "                               pd.Series(pred, name='Flood_Probability')], \n",
    "                               axis=1)\n",
    "\n",
    "# Display the combined results\n",
    "combined_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b7af002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.00040320658709055805\n",
      "Mean Absolute Error (MAE): 0.01579247136376033\n",
      "R-squared (R2): 0.8448773362840329\n",
      "Error Percentage: 3.1304398518836716%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, pred)  # Mean Squared Error\n",
    "mae = mean_absolute_error(y_test, pred)  # Mean Absolute Error\n",
    "r2 = r2_score(y_test, pred)  # R-squared value\n",
    "\n",
    "# Calculate error percentage\n",
    "error_percent = (mae / y_test.mean()) * 100\n",
    "\n",
    "# Display metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R2): {r2}\")\n",
    "print(f\"Error Percentage: {error_percent}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffc40c",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2591a0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0008964490804568145\n",
      "         Actual  Predicted\n",
      "1105809   0.560    0.51885\n",
      "442591    0.575    0.52935\n",
      "5434      0.510    0.53235\n",
      "82966     0.530    0.53995\n",
      "584893    0.590    0.57065\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined\n",
    "# Instantiate the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on X_test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Optionally, you can print out the predictions and actual values side by side\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "print(results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2280730",
   "metadata": {},
   "source": [
    "# KNearestNeighbor Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming your DataFrame is named df and your target variable is known\n",
    "# Example target variable, please adjust based on your context\n",
    "# y = df['TargetColumnName']  # Replace with your target column name\n",
    "# X = df.drop(columns=['TargetColumnName'])  # Drop the target column\n",
    "\n",
    "# Initialize the KNeighborsRegressor model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can adjust n_neighbors\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Optional: Display predictions alongside actual values\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "print(results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213cd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d14dd1-284d-4c80-8412-1f40e9d8f8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a65ca-961d-4812-b756-32fa54e897fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "db7cfb21-c6a4-48fe-b5b1-411fe3daba8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1117957 entries, 0 to 1117956\n",
      "Data columns (total 22 columns):\n",
      " #   Column                           Non-Null Count    Dtype  \n",
      "---  ------                           --------------    -----  \n",
      " 0   id                               1117957 non-null  int64  \n",
      " 1   MonsoonIntensity                 1117957 non-null  int64  \n",
      " 2   TopographyDrainage               1117957 non-null  int64  \n",
      " 3   RiverManagement                  1117957 non-null  int64  \n",
      " 4   Deforestation                    1117957 non-null  int64  \n",
      " 5   Urbanization                     1117957 non-null  int64  \n",
      " 6   ClimateChange                    1117957 non-null  int64  \n",
      " 7   DamsQuality                      1117957 non-null  int64  \n",
      " 8   Siltation                        1117957 non-null  int64  \n",
      " 9   AgriculturalPractices            1117957 non-null  int64  \n",
      " 10  Encroachments                    1117957 non-null  int64  \n",
      " 11  IneffectiveDisasterPreparedness  1117957 non-null  int64  \n",
      " 12  DrainageSystems                  1117957 non-null  int64  \n",
      " 13  CoastalVulnerability             1117957 non-null  int64  \n",
      " 14  Landslides                       1117957 non-null  int64  \n",
      " 15  Watersheds                       1117957 non-null  int64  \n",
      " 16  DeterioratingInfrastructure      1117957 non-null  int64  \n",
      " 17  PopulationScore                  1117957 non-null  int64  \n",
      " 18  WetlandLoss                      1117957 non-null  int64  \n",
      " 19  InadequatePlanning               1117957 non-null  int64  \n",
      " 20  PoliticalFactors                 1117957 non-null  int64  \n",
      " 21  FloodProbability                 1117957 non-null  float64\n",
      "dtypes: float64(1), int64(21)\n",
      "memory usage: 187.6 MB\n",
      "None\n",
      "                 id  MonsoonIntensity  TopographyDrainage  RiverManagement  \\\n",
      "count  1.117957e+06      1.117957e+06        1.117957e+06     1.117957e+06   \n",
      "mean   5.589780e+05      4.921450e+00        4.926671e+00     4.955322e+00   \n",
      "std    3.227265e+05      2.056387e+00        2.093879e+00     2.072186e+00   \n",
      "min    0.000000e+00      0.000000e+00        0.000000e+00     0.000000e+00   \n",
      "25%    2.794890e+05      3.000000e+00        3.000000e+00     4.000000e+00   \n",
      "50%    5.589780e+05      5.000000e+00        5.000000e+00     5.000000e+00   \n",
      "75%    8.384670e+05      6.000000e+00        6.000000e+00     6.000000e+00   \n",
      "max    1.117956e+06      1.600000e+01        1.800000e+01     1.600000e+01   \n",
      "\n",
      "       Deforestation  Urbanization  ClimateChange   DamsQuality     Siltation  \\\n",
      "count   1.117957e+06  1.117957e+06   1.117957e+06  1.117957e+06  1.117957e+06   \n",
      "mean    4.942240e+00  4.942517e+00   4.934093e+00  4.955878e+00  4.927791e+00   \n",
      "std     2.051689e+00  2.083391e+00   2.057742e+00  2.083063e+00  2.065992e+00   \n",
      "min     0.000000e+00  0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%     4.000000e+00  3.000000e+00   3.000000e+00  4.000000e+00  3.000000e+00   \n",
      "50%     5.000000e+00  5.000000e+00   5.000000e+00  5.000000e+00  5.000000e+00   \n",
      "75%     6.000000e+00  6.000000e+00   6.000000e+00  6.000000e+00  6.000000e+00   \n",
      "max     1.700000e+01  1.700000e+01   1.700000e+01  1.600000e+01  1.600000e+01   \n",
      "\n",
      "       AgriculturalPractices  ...  DrainageSystems  CoastalVulnerability  \\\n",
      "count           1.117957e+06  ...     1.117957e+06          1.117957e+06   \n",
      "mean            4.942619e+00  ...     4.946893e+00          4.953999e+00   \n",
      "std             2.068545e+00  ...     2.072333e+00          2.088899e+00   \n",
      "min             0.000000e+00  ...     0.000000e+00          0.000000e+00   \n",
      "25%             3.000000e+00  ...     4.000000e+00          3.000000e+00   \n",
      "50%             5.000000e+00  ...     5.000000e+00          5.000000e+00   \n",
      "75%             6.000000e+00  ...     6.000000e+00          6.000000e+00   \n",
      "max             1.600000e+01  ...     1.700000e+01          1.700000e+01   \n",
      "\n",
      "         Landslides    Watersheds  DeterioratingInfrastructure  \\\n",
      "count  1.117957e+06  1.117957e+06                 1.117957e+06   \n",
      "mean   4.931376e+00  4.929032e+00                 4.925907e+00   \n",
      "std    2.078287e+00  2.082395e+00                 2.064813e+00   \n",
      "min    0.000000e+00  0.000000e+00                 0.000000e+00   \n",
      "25%    3.000000e+00  3.000000e+00                 3.000000e+00   \n",
      "50%    5.000000e+00  5.000000e+00                 5.000000e+00   \n",
      "75%    6.000000e+00  6.000000e+00                 6.000000e+00   \n",
      "max    1.600000e+01  1.600000e+01                 1.700000e+01   \n",
      "\n",
      "       PopulationScore   WetlandLoss  InadequatePlanning  PoliticalFactors  \\\n",
      "count     1.117957e+06  1.117957e+06        1.117957e+06      1.117957e+06   \n",
      "mean      4.927520e+00  4.950859e+00        4.940587e+00      4.939004e+00   \n",
      "std       2.074176e+00  2.068696e+00        2.081123e+00      2.090350e+00   \n",
      "min       0.000000e+00  0.000000e+00        0.000000e+00      0.000000e+00   \n",
      "25%       3.000000e+00  4.000000e+00        3.000000e+00      3.000000e+00   \n",
      "50%       5.000000e+00  5.000000e+00        5.000000e+00      5.000000e+00   \n",
      "75%       6.000000e+00  6.000000e+00        6.000000e+00      6.000000e+00   \n",
      "max       1.800000e+01  1.900000e+01        1.600000e+01      1.600000e+01   \n",
      "\n",
      "       FloodProbability  \n",
      "count      1.117957e+06  \n",
      "mean       5.044803e-01  \n",
      "std        5.102610e-02  \n",
      "min        2.850000e-01  \n",
      "25%        4.700000e-01  \n",
      "50%        5.050000e-01  \n",
      "75%        5.400000e-01  \n",
      "max        7.250000e-01  \n",
      "\n",
      "[8 rows x 22 columns]\n",
      "id                                 0\n",
      "MonsoonIntensity                   0\n",
      "TopographyDrainage                 0\n",
      "RiverManagement                    0\n",
      "Deforestation                      0\n",
      "Urbanization                       0\n",
      "ClimateChange                      0\n",
      "DamsQuality                        0\n",
      "Siltation                          0\n",
      "AgriculturalPractices              0\n",
      "Encroachments                      0\n",
      "IneffectiveDisasterPreparedness    0\n",
      "DrainageSystems                    0\n",
      "CoastalVulnerability               0\n",
      "Landslides                         0\n",
      "Watersheds                         0\n",
      "DeterioratingInfrastructure        0\n",
      "PopulationScore                    0\n",
      "WetlandLoss                        0\n",
      "InadequatePlanning                 0\n",
      "PoliticalFactors                   0\n",
      "FloodProbability                   0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m mse_results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Predict on test data\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/pipx/venvs/jupyterlab/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/pipx/venvs/jupyterlab/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1231\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m   1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1224\u001b[0m     X,\n\u001b[1;32m   1225\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1230\u001b[0m )\n\u001b[0;32m-> 1231\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;66;03m# TODO(1.7) remove multi_class\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/pipx/venvs/jupyterlab/lib/python3.11/site-packages/sklearn/utils/multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    213\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m ]:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Check for missing values and basic statistics\n",
    "print(train_data.info())\n",
    "print(train_data.describe())\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Assuming 'FloodProbability' is the target variable\n",
    "X_train = train_data.drop(['FloodProbability'], axis=1)\n",
    "y_train = train_data['FloodProbability']\n",
    "\n",
    "# Assuming test_data does not contain the target variable\n",
    "X_test = test_data\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC()\n",
    "}\n",
    "\n",
    "# Train models and evaluate\n",
    "accuracy_results = {}\n",
    "mse_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    # Note: Replace y_test with actual target labels if available for test data\n",
    "    # Here, we're using train data for calculating accuracy and MSE\n",
    "    train_pred = model.predict(X_train)\n",
    "    accuracy = accuracy_score(y_train, train_pred)\n",
    "    mse = mean_squared_error(y_train, train_pred)\n",
    "    \n",
    "    # Store results\n",
    "    accuracy_results[name] = accuracy\n",
    "    mse_results[name] = mse\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "# Plotting results\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(list(accuracy_results.keys()), list(accuracy_results.values()), color='skyblue')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "\n",
    "# MSE plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(list(mse_results.keys()), list(mse_results.values()), color='salmon')\n",
    "plt.xlabel('Mean Squared Error')\n",
    "plt.title('Model MSE Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe63f6d-c31c-416c-bd7b-92dfa0ab0f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb8ad8-13f6-47c5-91b7-d42f3e94f59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5982513a-d9f1-4cb2-87ee-945ede3c9bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1117957 entries, 0 to 1117956\n",
      "Data columns (total 22 columns):\n",
      " #   Column                           Non-Null Count    Dtype  \n",
      "---  ------                           --------------    -----  \n",
      " 0   id                               1117957 non-null  int64  \n",
      " 1   MonsoonIntensity                 1117957 non-null  int64  \n",
      " 2   TopographyDrainage               1117957 non-null  int64  \n",
      " 3   RiverManagement                  1117957 non-null  int64  \n",
      " 4   Deforestation                    1117957 non-null  int64  \n",
      " 5   Urbanization                     1117957 non-null  int64  \n",
      " 6   ClimateChange                    1117957 non-null  int64  \n",
      " 7   DamsQuality                      1117957 non-null  int64  \n",
      " 8   Siltation                        1117957 non-null  int64  \n",
      " 9   AgriculturalPractices            1117957 non-null  int64  \n",
      " 10  Encroachments                    1117957 non-null  int64  \n",
      " 11  IneffectiveDisasterPreparedness  1117957 non-null  int64  \n",
      " 12  DrainageSystems                  1117957 non-null  int64  \n",
      " 13  CoastalVulnerability             1117957 non-null  int64  \n",
      " 14  Landslides                       1117957 non-null  int64  \n",
      " 15  Watersheds                       1117957 non-null  int64  \n",
      " 16  DeterioratingInfrastructure      1117957 non-null  int64  \n",
      " 17  PopulationScore                  1117957 non-null  int64  \n",
      " 18  WetlandLoss                      1117957 non-null  int64  \n",
      " 19  InadequatePlanning               1117957 non-null  int64  \n",
      " 20  PoliticalFactors                 1117957 non-null  int64  \n",
      " 21  FloodProbability                 1117957 non-null  float64\n",
      "dtypes: float64(1), int64(21)\n",
      "memory usage: 187.6 MB\n",
      "None\n",
      "                 id  MonsoonIntensity  TopographyDrainage  RiverManagement  \\\n",
      "count  1.117957e+06      1.117957e+06        1.117957e+06     1.117957e+06   \n",
      "mean   5.589780e+05      4.921450e+00        4.926671e+00     4.955322e+00   \n",
      "std    3.227265e+05      2.056387e+00        2.093879e+00     2.072186e+00   \n",
      "min    0.000000e+00      0.000000e+00        0.000000e+00     0.000000e+00   \n",
      "25%    2.794890e+05      3.000000e+00        3.000000e+00     4.000000e+00   \n",
      "50%    5.589780e+05      5.000000e+00        5.000000e+00     5.000000e+00   \n",
      "75%    8.384670e+05      6.000000e+00        6.000000e+00     6.000000e+00   \n",
      "max    1.117956e+06      1.600000e+01        1.800000e+01     1.600000e+01   \n",
      "\n",
      "       Deforestation  Urbanization  ClimateChange   DamsQuality     Siltation  \\\n",
      "count   1.117957e+06  1.117957e+06   1.117957e+06  1.117957e+06  1.117957e+06   \n",
      "mean    4.942240e+00  4.942517e+00   4.934093e+00  4.955878e+00  4.927791e+00   \n",
      "std     2.051689e+00  2.083391e+00   2.057742e+00  2.083063e+00  2.065992e+00   \n",
      "min     0.000000e+00  0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%     4.000000e+00  3.000000e+00   3.000000e+00  4.000000e+00  3.000000e+00   \n",
      "50%     5.000000e+00  5.000000e+00   5.000000e+00  5.000000e+00  5.000000e+00   \n",
      "75%     6.000000e+00  6.000000e+00   6.000000e+00  6.000000e+00  6.000000e+00   \n",
      "max     1.700000e+01  1.700000e+01   1.700000e+01  1.600000e+01  1.600000e+01   \n",
      "\n",
      "       AgriculturalPractices  ...  DrainageSystems  CoastalVulnerability  \\\n",
      "count           1.117957e+06  ...     1.117957e+06          1.117957e+06   \n",
      "mean            4.942619e+00  ...     4.946893e+00          4.953999e+00   \n",
      "std             2.068545e+00  ...     2.072333e+00          2.088899e+00   \n",
      "min             0.000000e+00  ...     0.000000e+00          0.000000e+00   \n",
      "25%             3.000000e+00  ...     4.000000e+00          3.000000e+00   \n",
      "50%             5.000000e+00  ...     5.000000e+00          5.000000e+00   \n",
      "75%             6.000000e+00  ...     6.000000e+00          6.000000e+00   \n",
      "max             1.600000e+01  ...     1.700000e+01          1.700000e+01   \n",
      "\n",
      "         Landslides    Watersheds  DeterioratingInfrastructure  \\\n",
      "count  1.117957e+06  1.117957e+06                 1.117957e+06   \n",
      "mean   4.931376e+00  4.929032e+00                 4.925907e+00   \n",
      "std    2.078287e+00  2.082395e+00                 2.064813e+00   \n",
      "min    0.000000e+00  0.000000e+00                 0.000000e+00   \n",
      "25%    3.000000e+00  3.000000e+00                 3.000000e+00   \n",
      "50%    5.000000e+00  5.000000e+00                 5.000000e+00   \n",
      "75%    6.000000e+00  6.000000e+00                 6.000000e+00   \n",
      "max    1.600000e+01  1.600000e+01                 1.700000e+01   \n",
      "\n",
      "       PopulationScore   WetlandLoss  InadequatePlanning  PoliticalFactors  \\\n",
      "count     1.117957e+06  1.117957e+06        1.117957e+06      1.117957e+06   \n",
      "mean      4.927520e+00  4.950859e+00        4.940587e+00      4.939004e+00   \n",
      "std       2.074176e+00  2.068696e+00        2.081123e+00      2.090350e+00   \n",
      "min       0.000000e+00  0.000000e+00        0.000000e+00      0.000000e+00   \n",
      "25%       3.000000e+00  4.000000e+00        3.000000e+00      3.000000e+00   \n",
      "50%       5.000000e+00  5.000000e+00        5.000000e+00      5.000000e+00   \n",
      "75%       6.000000e+00  6.000000e+00        6.000000e+00      6.000000e+00   \n",
      "max       1.800000e+01  1.900000e+01        1.600000e+01      1.600000e+01   \n",
      "\n",
      "       FloodProbability  \n",
      "count      1.117957e+06  \n",
      "mean       5.044803e-01  \n",
      "std        5.102610e-02  \n",
      "min        2.850000e-01  \n",
      "25%        4.700000e-01  \n",
      "50%        5.050000e-01  \n",
      "75%        5.400000e-01  \n",
      "max        7.250000e-01  \n",
      "\n",
      "[8 rows x 22 columns]\n",
      "id                                 0\n",
      "MonsoonIntensity                   0\n",
      "TopographyDrainage                 0\n",
      "RiverManagement                    0\n",
      "Deforestation                      0\n",
      "Urbanization                       0\n",
      "ClimateChange                      0\n",
      "DamsQuality                        0\n",
      "Siltation                          0\n",
      "AgriculturalPractices              0\n",
      "Encroachments                      0\n",
      "IneffectiveDisasterPreparedness    0\n",
      "DrainageSystems                    0\n",
      "CoastalVulnerability               0\n",
      "Landslides                         0\n",
      "Watersheds                         0\n",
      "DeterioratingInfrastructure        0\n",
      "PopulationScore                    0\n",
      "WetlandLoss                        0\n",
      "InadequatePlanning                 0\n",
      "PoliticalFactors                   0\n",
      "FloodProbability                   0\n",
      "dtype: int64\n",
      "Logistic Regression - Accuracy: 0.9887, MSE: 0.0113\n",
      "Random Forest - Accuracy: 1.0000, MSE: 0.0000\n",
      "Decision Tree - Accuracy: 1.0000, MSE: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Check for missing values and basic statistics\n",
    "print(train_data.info())\n",
    "print(train_data.describe())\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Assuming 'FloodProbability' is the target variable\n",
    "X_train = train_data.drop(['FloodProbability'], axis=1)\n",
    "y_train = train_data['FloodProbability']\n",
    "\n",
    "# Convert continuous target to discrete classes (example)\n",
    "# Adjust the binning logic based on your data distribution\n",
    "y_train = pd.cut(y_train, bins=[-float('inf'), 0.3, 0.6, float('inf')], labels=[0, 1, 2])\n",
    "\n",
    "# Assuming test_data does not contain the target variable\n",
    "X_test = test_data\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC()\n",
    "}\n",
    "\n",
    "# Train models and evaluate\n",
    "accuracy_results = {}\n",
    "mse_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on train data\n",
    "    train_pred = model.predict(X_train)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_train, train_pred)\n",
    "    mse = mean_squared_error(y_train, train_pred)\n",
    "    \n",
    "    # Store results\n",
    "    accuracy_results[name] = accuracy\n",
    "    mse_results[name] = mse\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "# Plotting results\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(list(accuracy_results.keys()), list(accuracy_results.values()), color='skyblue')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "\n",
    "# MSE plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(list(mse_results.keys()), list(mse_results.values()), color='salmon')\n",
    "plt.xlabel('Mean Squared Error')\n",
    "plt.title('Model MSE Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0aad03-f448-487a-968c-803353c06a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Check for missing values and basic statistics\n",
    "print(train_data.info())\n",
    "print(train_data.describe())\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Assuming 'FloodProbability' is the target variable\n",
    "X_train = train_data.drop(['FloodProbability'], axis=1)\n",
    "y_train = train_data['FloodProbability']\n",
    "\n",
    "# Convert continuous 'FloodProbability' to binary classes\n",
    "# Set threshold, here it is 0.5\n",
    "threshold = 0.5\n",
    "y_train = (y_train >= threshold).astype(int)  # 0 if < threshold, 1 if >= threshold\n",
    "\n",
    "# Assuming test_data does not contain the target variable\n",
    "X_test = test_data\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC()\n",
    "}\n",
    "\n",
    "# Train models and evaluate\n",
    "accuracy_results = {}\n",
    "mse_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on train data\n",
    "    train_pred = model.predict(X_train)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_train, train_pred)\n",
    "    mse = mean_squared_error(y_train, train_pred)\n",
    "    \n",
    "    # Store results\n",
    "    accuracy_results[name] = accuracy\n",
    "    mse_results[name] = mse\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "# Plotting results\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(list(accuracy_results.keys()), list(accuracy_results.values()), color='skyblue')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "\n",
    "# MSE plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(list(mse_results.keys()), list(mse_results.values()), color='salmon')\n",
    "plt.xlabel('Mean Squared Error')\n",
    "plt.title('Model MSE Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616f6c5-f12f-4ae8-aa95-aeb333b0c748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
